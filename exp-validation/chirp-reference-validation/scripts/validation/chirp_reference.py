#!/usr/bin/env python3
"""
Chirp Reference Module
======================
Load, cross-validate, and provide chirp-derived MIC-MIC tau references
for use in validation Phase 1-4 re-runs.

Data sources:
  - dataset/chirp/results/chirp_calibration_summary.json
  - dataset/chirp_2/results/chirp_calibration_summary.json

Both generated by dataset/chirp/validate_chirp_calibration.py using
event-windowed GCC-PHAT with guided peak search and 3-pair consistency gating.
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, Tuple

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

# Map speech folder IDs to chirp position labels
SPEECH_TO_CHIRP = {
    '18': '+0.8',
    '19': '+0.4',
    '20': '+0.0',
    '21': '-0.4',
    '22': '-0.8',
}

# Reverse mapping
CHIRP_TO_SPEECH = {v: k for k, v in SPEECH_TO_CHIRP.items()}

# Speaker x-coordinates (metres)
POSITION_X = {
    '+0.8': 0.8,
    '+0.4': 0.4,
    '+0.0': 0.0,
    '-0.4': -0.4,
    '-0.8': -0.8,
}

# Geometry (metres)
MIC_LEFT = (-0.7, 2.0)
MIC_RIGHT = (0.7, 2.0)
LDV_POS = (0.0, 0.5)
SPEED_OF_SOUND = 343.0

# Minimum events for a chirp reference to be considered reliable
MIN_EVENTS_RELIABLE = 2


# ---------------------------------------------------------------------------
# Geometric fallback
# ---------------------------------------------------------------------------

def geometric_tau_ms(speaker_x: float) -> float:
    """Compute MIC-MIC tau (ms) from geometry alone.

    Convention: tau(L,R) = (d_L - d_R) / c
    Matches the chirp calibration convention where gcc_phat(sig_L, sig_R)
    returns positive tau when LEFT-MIC is farther (speaker on positive side).
    """
    import math
    d_l = math.sqrt((speaker_x - MIC_LEFT[0])**2 + MIC_LEFT[1]**2)
    d_r = math.sqrt((speaker_x - MIC_RIGHT[0])**2 + MIC_RIGHT[1]**2)
    return (d_l - d_r) / SPEED_OF_SOUND * 1000.0


# ---------------------------------------------------------------------------
# Load calibration JSON
# ---------------------------------------------------------------------------

def load_calibration(chirp_root: Path) -> Optional[dict]:
    """Load chirp_calibration_summary.json from a chirp dataset root."""
    json_path = chirp_root / 'results' / 'chirp_calibration_summary.json'
    if not json_path.exists():
        print(f"  [WARN] Calibration file not found: {json_path}")
        return None
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def find_project_root_with_dataset(start: Path) -> Path:
    """Walk upward from start to find a directory containing dataset/."""
    start = start.resolve()
    for parent in [start] + list(start.parents):
        if (parent / 'dataset').exists():
            return parent
    raise FileNotFoundError(f"Could not find dataset/ above {start}")


def extract_micmic_tau(calibration: dict) -> Dict[str, dict]:
    """
    Extract per-position MIC-MIC tau info from calibration data.

    Returns dict[position_label] -> {
        'tau_median_ms': float,
        'events_used': int,
        'events_detected': int,
        'psr_median_db': float,
        'reliable': bool
    }
    """
    result = {}
    positions = calibration.get('positions', {})
    for pos_label, pos_data in positions.items():
        summary = pos_data.get('summary', {})
        pairs = summary.get('pairs', {})
        micmic = pairs.get('LEFT-MIC_RIGHT-MIC', {})

        events_used = summary.get('events_used', 0)
        events_detected = summary.get('events_detected', 0)

        result[pos_label] = {
            'tau_median_ms': micmic.get('tau_median_ms', None),
            'tau_geom_ms': micmic.get('tau_geom_ms', None),
            'err_median_ms': micmic.get('err_median_ms', None),
            'psr_median_db': micmic.get('psr_median_db', None),
            'events_used': events_used,
            'events_detected': events_detected,
            'reliable': events_used >= MIN_EVENTS_RELIABLE,
        }
    return result


def extract_sensor_delays(calibration: dict) -> dict:
    """Extract per-sensor delay estimates from calibration data."""
    return calibration.get('summary', {}).get('sensor_delays_ms', {})


# ---------------------------------------------------------------------------
# Cross-validation
# ---------------------------------------------------------------------------

def cross_validate(
    chirp1_tau: Dict[str, dict],
    chirp2_tau: Dict[str, dict],
) -> dict:
    """
    Compare chirp vs chirp_2 MIC-MIC tau values.

    Returns per-position comparison and overall consistency metrics.
    """
    comparisons = {}
    all_positions = sorted(set(chirp1_tau.keys()) | set(chirp2_tau.keys()))

    for pos in all_positions:
        c1 = chirp1_tau.get(pos, {})
        c2 = chirp2_tau.get(pos, {})

        tau1 = c1.get('tau_median_ms')
        tau2 = c2.get('tau_median_ms')
        r1 = c1.get('reliable', False)
        r2 = c2.get('reliable', False)

        geo = geometric_tau_ms(POSITION_X.get(pos, 0.0))

        comp = {
            'chirp_tau_ms': tau1,
            'chirp2_tau_ms': tau2,
            'geometric_tau_ms': geo,
            'chirp_reliable': r1,
            'chirp2_reliable': r2,
            'chirp_events_used': c1.get('events_used', 0),
            'chirp2_events_used': c2.get('events_used', 0),
        }

        if tau1 is not None and tau2 is not None:
            comp['discrepancy_ms'] = abs(tau1 - tau2)
            comp['mean_tau_ms'] = (tau1 + tau2) / 2.0
            comp['chirp_vs_geom_ms'] = abs(tau1 - geo)
            comp['chirp2_vs_geom_ms'] = abs(tau2 - geo)

        # Determine best reference
        if r1 and r2:
            comp['reference_source'] = 'chirp_mean'
            comp['reference_tau_ms'] = comp.get('mean_tau_ms', tau1)
        elif r1:
            comp['reference_source'] = 'chirp_only'
            comp['reference_tau_ms'] = tau1
        elif r2:
            comp['reference_source'] = 'chirp2_only'
            comp['reference_tau_ms'] = tau2
        else:
            comp['reference_source'] = 'geometric_fallback'
            comp['reference_tau_ms'] = geo

        comparisons[pos] = comp

    # Overall summary
    reliable_discrepancies = [
        c['discrepancy_ms'] for c in comparisons.values()
        if c.get('chirp_reliable') and c.get('chirp2_reliable')
        and 'discrepancy_ms' in c
    ]

    summary = {
        'n_positions': len(all_positions),
        'n_both_reliable': sum(
            1 for c in comparisons.values()
            if c.get('chirp_reliable') and c.get('chirp2_reliable')
        ),
        'n_geometric_fallback': sum(
            1 for c in comparisons.values()
            if c.get('reference_source') == 'geometric_fallback'
        ),
    }
    if reliable_discrepancies:
        summary['max_discrepancy_ms'] = max(reliable_discrepancies)
        summary['mean_discrepancy_ms'] = sum(reliable_discrepancies) / len(reliable_discrepancies)

    return {
        'timestamp': datetime.now().isoformat(),
        'summary': summary,
        'positions': comparisons,
    }


# ---------------------------------------------------------------------------
# Public API
# ---------------------------------------------------------------------------

def get_chirp_references(
    dataset_root: Path,
    allow_geometric_fallback: bool = True,
) -> Tuple[Dict[str, float], dict]:
    """
    Main entry point: load chirp references for all 5 positions.

    Args:
        dataset_root: Root of the LDVReorientation project
            (contains dataset/chirp/ and dataset/chirp_2/)
        allow_geometric_fallback: If True, use geometric estimation
            for positions without reliable chirp data.

    Returns:
        references: dict[speech_position_id] -> tau_ms
        report: full cross-validation report dict
    """
    chirp_root = dataset_root / 'dataset' / 'chirp'
    chirp2_root = dataset_root / 'dataset' / 'chirp_2'

    # Load calibration data
    cal1 = load_calibration(chirp_root)
    cal2 = load_calibration(chirp2_root)

    if cal1 is None and cal2 is None:
        raise FileNotFoundError(
            "Neither chirp nor chirp_2 calibration results found. "
            f"Searched: {chirp_root}/results/, {chirp2_root}/results/"
        )

    # Extract MIC-MIC tau per position
    tau1 = extract_micmic_tau(cal1) if cal1 else {}
    tau2 = extract_micmic_tau(cal2) if cal2 else {}

    # Cross-validate
    report = cross_validate(tau1, tau2)

    # Build speech-position reference table
    references = {}
    for speech_id, chirp_label in SPEECH_TO_CHIRP.items():
        pos_data = report['positions'].get(chirp_label, {})
        ref_source = pos_data.get('reference_source', 'geometric_fallback')
        ref_tau = pos_data.get('reference_tau_ms')

        if ref_source == 'geometric_fallback' and not allow_geometric_fallback:
            print(f"  [SKIP] Position {speech_id} ({chirp_label}): "
                  f"no reliable chirp reference, geometric fallback disabled")
            continue

        if ref_tau is not None:
            references[speech_id] = ref_tau

    # Also extract sensor delays
    delays1 = extract_sensor_delays(cal1) if cal1 else {}
    delays2 = extract_sensor_delays(cal2) if cal2 else {}
    report['sensor_delays'] = {
        'chirp': delays1,
        'chirp_2': delays2,
    }

    return references, report


# ---------------------------------------------------------------------------
# CLI: standalone cross-validation
# ---------------------------------------------------------------------------

def main():
    """Run chirp cross-validation and print results."""
    import argparse

    parser = argparse.ArgumentParser(
        description='Cross-validate chirp and chirp_2 MIC-MIC tau references'
    )
    parser.add_argument(
        '--dataset_root',
        type=Path,
        default=Path(__file__).resolve().parents[2],
        help='Project root or dataset root containing chirp/ and chirp_2/'
    )
    parser.add_argument(
        '--out_dir',
        type=Path,
        default=None,
        help='Output directory for cross-validation results'
    )
    args = parser.parse_args()

    dataset_root = args.dataset_root
    if (dataset_root / 'chirp').exists():
        project_root = dataset_root.parent
    elif (dataset_root / 'dataset').exists():
        project_root = dataset_root
    else:
        project_root = find_project_root_with_dataset(dataset_root)

    print("=" * 60)
    print("Chirp Reference Cross-Validation")
    print("=" * 60)

    references, report = get_chirp_references(project_root)

    # Print results
    print("\n--- Reference Table ---")
    print(f"{'Speech ID':<12} {'Chirp Label':<12} {'tau (ms)':<12} {'Source'}")
    print("-" * 52)

    for speech_id in sorted(references.keys()):
        chirp_label = SPEECH_TO_CHIRP[speech_id]
        tau = references[speech_id]
        pos_data = report['positions'].get(chirp_label, {})
        source = pos_data.get('reference_source', '?')
        print(f"{speech_id:<12} {chirp_label:<12} {tau:+.4f}      {source}")

    print(f"\n--- Cross-Validation Summary ---")
    summary = report.get('summary', {})
    print(f"  Positions with both datasets reliable: {summary.get('n_both_reliable', 0)}/5")
    print(f"  Positions using geometric fallback:    {summary.get('n_geometric_fallback', 0)}/5")
    if 'max_discrepancy_ms' in summary:
        print(f"  Max chirp-vs-chirp_2 discrepancy:     {summary['max_discrepancy_ms']:.4f} ms")
        print(f"  Mean chirp-vs-chirp_2 discrepancy:    {summary['mean_discrepancy_ms']:.4f} ms")

    print(f"\n--- Sensor Delays ---")
    for dataset_name in ['chirp', 'chirp_2']:
        delays = report.get('sensor_delays', {}).get(dataset_name, {})
        if delays:
            ldv = delays.get('LDV', '?')
            right = delays.get('RIGHT-MIC', '?')
            print(f"  {dataset_name}: LDV={ldv:.4f} ms, RIGHT-MIC={right:.4f} ms"
                  if isinstance(ldv, (int, float)) else
                  f"  {dataset_name}: {delays}")

    # Save results
    if args.out_dir:
        out_dir = args.out_dir
    else:
        out_dir = Path(__file__).resolve().parents[2] / 'results' / 'chirp_cross_validation'

    out_dir.mkdir(parents=True, exist_ok=True)
    out_file = out_dir / 'cross_validation.json'
    with open(out_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, default=str)
    print(f"\n  Results saved to: {out_file}")

    ref_file = out_dir / 'chirp_references.json'
    with open(ref_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'references': references,
            'position_mapping': SPEECH_TO_CHIRP,
            'description': 'MIC-MIC tau references from chirp calibration',
        }, f, indent=2)
    print(f"  References saved to: {ref_file}")

    return 0


if __name__ == '__main__':
    sys.exit(main())
